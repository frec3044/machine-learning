---
title: "Machine learning steps"
author: "Quinn Thomas"
format:
  html:
    embed-resources: true
---

## Step 1: Obtain data

Read in data to memory.  In the course, we have accessed data from CSV files, Excel files, databases, web addresses, and behind an API. 

## Step 2: Pre-process data

### Split data: divide data into the training and test sets. 

- You will use the training set to fit (train) your model and the testing set to evaluate the model's performance.
We only want to evaluate our model using data that was not used in its training. Otherwise, we can only say that the model is good at fitting the data that was used to train it. This is not helpful for understanding how it would perform as a tool to generate new predictions.
You want most of your data in the training set because machine learning models can be quite "hungry for data" (e.g., they need a large dataset to find a good fit).
- A typical split is 80% training and 20% testing, but there isn't a required split. 
- Data are randomly assigned to the two splits.
- Your data may have obvious groupings that you want to be equally represented in both the training and testing sets.  For example, if you have cats and dogs as a variable, and you are using the model to predict tail length as a function of species and height, you may want to be sure that your training set is not randomly full of dogs because that means it may not predict the cats well in the testing set.  You can prevent this by defining the `strata` used when assigning the training and testing sets.
- If your data does not have groupings that you want to have evenly distributed in the training and testing set, you do not need to use a strata

### Recipes: Modify predictors/features/covariates/independent variables for analysis

  - Modify the data set so that variables are correctly formatted for a particular model. For example, a linear regression requires groups to be dummy variables. Therefore, a column called "ecosystem" with two values: "forest" and "grass" would be converted to two columns: ecosystem_forest with a value of 0 or 1 and ecosystem_grass with a value of 0 and 1)
  - Removing highly correlated predictors
  - Rescaling predictors (e.g., converting to 0 mean and 1 standard deviation)
  - transforming predictors using a function like `log()`.

## Step 3: Specify model and workflow

A workflow combines the model and recipe into a single "object" that can be used for training, testing, and predicting new data.

  - Define model type: linear regression, regression tree, neutral net, etc.
  - Define model engine: particular R package (`lm`, `ranger`, etc.)
  - Define model mode: regression or classification
  - Define workflow: combine recipe and model definition

## Step 4: Train model

  - Tune hyper-parameters: hyper-parameters are configuration settings that govern how a particular ML method is fit to data. They are called "hyper" because "regular" parameters are the parameters within the model learned by the ML method.  For example, a method called "random forecast" requires a hyper-parameter that controls the minimum size of a regression tree that is allowed.  This parameter (called `min_n`) could be directly provided by you or could be tuned.  The tuning process involves repeatedly fitting the model using different values of the hyper-parameter and using the hyper-parameter values that yield the best fit to the data. Importantly, not all ML methods have hyper-parameters (e.g., linear regression using the `lm` engine does not have hyper-parameters).  We don't tune hyperparameters in this example. See `example-with-tuning.Rmd` for an extension of this application that includes hyperparameter tuning.
  
  - Fit model (using best hyper-parameter if they are tuned).  The model is fit to the training data.

## Step 5: Predict

  - Predict testing data using the model that was fit to the training data. This step is critical because we only want to evaluate our model using data that the model has not used yet.
  - Predictions are quite easy using the `predict()` function.
  
## Step 6: Evaluate model

  - It is important to use the appropriate metrics to evaluate how the model performs.  Some metrics only apply to classification problems, and others only apply to regression problems. A list of metric types can be found [here](https://yardstick.tidymodels.org/articles/metric-types.html)
  We will focus on root-mean-squared error (`rmse`), a metric that subtracts each observation from the predictions, squares it, averages all the squared errors for all the data points, and then takes the square root of the mean squared error.  
  - R-squared (`rsq`) is another metric that we used in the lake ice module.
  
## Step 7: Deploy model

  - One of the main points of using machine learning is to develop a tool that can be used with new predictors to predict data that wasn't involved in the training and testing.  These are new data have all the columns necessary to make predictions but lack data in the column you are trying to predict.  
  - This step is simple because it involves using the `predict()` function with the same trained model but with new data.
  
# Application: Predicting biomass in NEON data

In the example application, we will use the vegetation carbon stock data that was used in the carbon stock model. Our goal is to predict the mean carbon stock of each plot in the NEON data. This will allow us to build a model that could be used to predict carbon stocks at locations other than NEON and potentially provide a prediction tool for land managers.

You will use the following packages.

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
tidymodels_prefer() #so that functions in the tidymodels have priority if others have the same name.
set.seed(100) #for random number generation
```

## Step 1: Obtain data

The data are from the National Ecological Observatory Network, the DayMet project (meteorology data), and NASA's MODIS satellite.  They have been combined to provide the woody vegetation carbon stocks for each NEON plot and the associated meteorology, land-use classification, and normalized vegetation index (from MODIS).

```{r}
biomass_data <- read_csv("data/neon_biomass.csv", show_col_types = FALSE)
```

In this example analysis, we will use only three columns. `plotID` is the plot's identifier, `nlcdClass` is the plot's land-cover classification, and `plot_kgCm2` is the plot's vegetation carbon stock (kgC/m2). We will use `nlcdClass` to predict `plot_kgCm2` for each `plotID`.

```{r}
biomass_data <- biomass_data |> 
  select(plotID, nlcdClass, plot_kgCm2)
```

## Step 2:  Pre-process data

### Split data into training/testing sets 

We are going to split the data into training and testing sets using the `initial_split` function.  `prop = 0.80` says to use 80% of the data in the training set. Since we want the training and test sets to represent all the types of `nlcdClass`, we include it as a `strata`.



```{r}
split <- initial_split(biomass_data, 
                       prop = 0.80, 
                       strata = nlcdClass)
```

**Important note: you will not always use a strata (this has confused students in the past).** If your data does not have groupings that you want to have evenly distributed in the training and testing set, you do not need to use a strata.  This case you would have `split <- initial_split(biomass_data, prop = 0.80)`)

Our split should reflect the 80/20 that we defined using `prop`

```{r}
split
```

To get the training and testing data, we need to apply the `training()` and `testing()` functions to the split.

```{r}
train_data <- training(split)
test_data <- testing(split)
```

You can see that `train_data` is a data frame that we can work with.

```{r}
train_data
```

### Feature engineering using a recipe

 - Requires starting with a dataset that is used to provide the columns.
 - A formula with the dependent variable and the predictors.  If `.` is used as the predictor, that means using all columns other than the dependent variable.
 - Steps that modify the data
 
 We will use the following steps:
 - `step_rm` because we don't want to use the identifier of the plot in the fitting.
 - `step_other` because there are rare land-use classes that we want to lump together.  This creates an "other" class.
 - `step_dummy` because linear regression requires classes to be dummy variables. For example, a linear regression requires groups to be dummy variables. Therefore, a column called "ecosystem" with two values: "forest" and "grass" would be converted to two columns: ecosystem_forest with a value of 0 or 1 and ecosystem_grass with a value of 0 and 1)
 
 [Here are the different recipe steps used above](https://recipes.tidymodels.org/reference/index.html)

- [Add dummy variables](https://recipes.tidymodels.org/reference/index.html#step-functions-dummy-variables-and-encodings)
- [Filter rows and select columns](https://recipes.tidymodels.org/reference/index.html#step-functions-filters)

Here is our recipe:

```{r}
biomass_recipe <- train_data |> 
  recipe(plot_kgCm2 ~ . ) |> 
  step_rm(plotID) |>
  step_other(nlcdClass) |>
  step_dummy(nlcdClass)
```

The recipe should show the steps that will be performed when applying it. Importantly, these steps have not yet been applied; we just have a recipe for what to do.

```{r}
biomass_recipe
```

## Step 3: Specify model, engine, and workflow

We need to create the model and engine that we will use. In this example, we are using `linear_reg` with the mode of `regression` (as opposed to `classification`). Setting the mode for linear regression is actually not necessary because it only allows regressions, but it is included here for completeness. 

The engine is `lm` because we are using the standard R function `lm`.  We could other functions for linear regression modeling, and they would be specified as a different engine.

```{r}
linear_mod <- 
  linear_reg(mode = "regression") |> 
  set_engine("lm")
```

You will see the model, mode, and engine in the model object

```{r}
linear_mod 
```

We now combine the model and the recipe to make a workflow that can be used to fit the training and testing data. `workflow()` initiates the workflow, and `add_model` and `add_recipe` add those components to it. Importantly, the workflow has not yet been applied; we just have a description of what to do.

```{r}
biomass_wflow <-
  workflow() |> 
  add_model(linear_mod) |> 
  add_recipe(biomass_recipe)
```

You can see that the workflow object has all the components together

```{r}
biomass_wflow
```

## Step 4: Train model on Training Data

We will use the workflow object to train the model. We need to provide the workflow object and the dataset to the fit function to fit (i.e., train the model)

```{r}
biomass_fit <- biomass_wflow |> 
  fit(data = train_data)
```

You can see that the fit object is the workflow object + the results of the model fitting

```{r}
biomass_fit
```

## Step 5: Predict Test Data

Now we will predict the testing data using the model that was fit to the training data.

```{r}
predictions <- predict(biomass_fit, 
                       new_data = test_data)
```

The predictions are a single column called `.pred`

```{r}
predictions
```

We need to combine the `.pred` column with the testing data using the `bind_cols` function

```{r}
pred_test <- bind_cols(test_data, predictions)
```

Now we have a data frame with the prediction and all the predictors used to predict it and other identifying info (like `plotID`)

```{r}
pred_test
```

## Step 6: Evaluate model

We will evaluate the performance of our predictions of the testing data using two metrics (`rmse` and `rsq`).  The function `metric_set` defines the set of metrics we will be using.  It creates a function called `multi_metric()` that we will use to calculate the metrics.  We pipe in the predicted test data (`pred_test`) and tell the function that our truth (i.e., observed data) is the `plot_kgCm2` column and the predictions (i.e., `estimate`) is the `.pred` column

```{r}
multi_metric <- metric_set(rmse, rsq)

metric_table <- pred_test |> 
  multi_metric(truth = plot_kgCm2, 
               estimate = .pred)
```

The resulting table has the metrics for evaluation

```{r}
metric_table
```

## Step 7: Deploy model

The final step is to apply your model to predict new data. 

Now read in the new data.  

```{r}
new_data <- read_csv("data/neon_biomass_new.csv", show_col_types = FALSE)

new_data <- new_data |> 
  select(plotID, nlcdClass, plot_kgCm2)
```

You will notice that the plot_kgCm2 is all `NA` because you don't know the plot's carbon stock (we are predicting it).

```{r}
submit_data
```

As in "Step 5: Predict Test Data", use the model that was fit on the training data (`biomass_fit`) to predict the new data.

```{r}
new_predictions <- predict(biomass_fit, new_data = new_data)
```

Now create a data frame with the new data, predictions, and your name. 

**Be sure to add your name to the `mutate()`**

```{r}
new_predicted <- bind_cols(new_data, new_predictions) |>
  mutate(name = "ADD YOUR NAME HERE") |>
  select(plotID, name, .pred)
```

Write these predictions to a CSV file

```{r}
write_csv(new_predicted, file = "predictions.csv")
```

# Assignment

Your assignment is divided into two Quarto markdown document files that use data that you have already seen in the previous modules.

1) `assignment-part-1.qmd` challenges you to translate the linear regression that you did in the lake ice module following the tidymodel machine learning format presented in this Rmd

2) `assignment-part-2.qmd` challenges you to develop your own machine learning model to predict the carbon stock data from the forest carbon module.




